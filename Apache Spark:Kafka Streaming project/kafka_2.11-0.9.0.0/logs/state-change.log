[2016-01-20 20:00:45,280] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2016-01-20 20:01:31,398] TRACE Controller 0 epoch 2 started leader election for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,415] ERROR Controller 0 epoch 2 initiated state change for partition [twitterStream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterStream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:681)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController.startup(KafkaController.scala:677)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:188)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-01-20 20:01:31,418] TRACE Controller 0 epoch 2 started leader election for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,429] ERROR Controller 0 epoch 2 initiated state change for partition [twitterstream,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [twitterstream,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply$mcZ$sp(ZookeeperLeaderElector.scala:50)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.server.ZookeeperLeaderElector$$anonfun$startup$1.apply(ZookeeperLeaderElector.scala:48)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.server.ZookeeperLeaderElector.startup(ZookeeperLeaderElector.scala:48)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply$mcV$sp(KafkaController.scala:681)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.controller.KafkaController$$anonfun$startup$1.apply(KafkaController.scala:677)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController.startup(KafkaController.scala:677)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:188)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:37)
	at kafka.Kafka$.main(Kafka.scala:67)
	at kafka.Kafka.main(Kafka.scala)
[2016-01-20 20:01:31,610] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-20 20:01:31,611] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition twitterStream-0 (state.change.logger)
[2016-01-20 20:01:31,644] TRACE Controller 0 epoch 2 changed state of replica 0 for partition [twitterStream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-01-20 20:01:31,645] TRACE Controller 0 epoch 2 changed state of replica 0 for partition [twitterstream,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-01-20 20:01:31,646] TRACE Controller 0 epoch 2 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,646] TRACE Controller 0 epoch 2 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,665] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-20 20:01:31,665] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition twitterStream-0 (state.change.logger)
[2016-01-20 20:01:31,667] TRACE Controller 0 epoch 2 started leader election for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,683] TRACE Controller 0 epoch 2 elected leader 0 for Offline partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,686] TRACE Controller 0 epoch 2 changed partition [twitterStream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-01-20 20:01:31,687] TRACE Controller 0 epoch 2 started leader election for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,695] TRACE Controller 0 epoch 2 elected leader 0 for Offline partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,699] TRACE Controller 0 epoch 2 changed partition [twitterstream,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-01-20 20:01:31,699] TRACE Controller 0 epoch 2 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2) to broker 0 for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,699] TRACE Controller 0 epoch 2 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2) to broker 0 for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,700] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2) to broker 0 for partition twitterstream-0 (state.change.logger)
[2016-01-20 20:01:31,700] TRACE Controller 0 epoch 2 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2) to broker 0 for partition twitterStream-0 (state.change.logger)
[2016-01-20 20:01:31,729] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [twitterStream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 0 (state.change.logger)
[2016-01-20 20:01:31,729] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 0 (state.change.logger)
[2016-01-20 20:01:31,737] TRACE Controller 0 epoch 2 received response {error_code=0} for a request sent to broker Node(0, 10.139.56.24, 9092) (state.change.logger)
[2016-01-20 20:01:31,799] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) correlation id 1 from controller 0 epoch 2 for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,800] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) correlation id 1 from controller 0 epoch 2 for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,805] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,805] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,832] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 2 with correlation id 1 for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,834] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 0 epoch 2 with correlation id 1 for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,836] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,836] TRACE Broker 0 completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,842] TRACE Controller 0 epoch 2 received response {error_code=0,partitions=[{topic=twitterStream,partition=0,error_code=0},{topic=twitterstream,partition=0,error_code=0}]} for a request sent to broker Node(0, 10.139.56.24, 9092) (state.change.logger)
[2016-01-20 20:01:31,845] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [twitterStream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2016-01-20 20:01:31,845] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2016-01-20 20:01:31,846] TRACE Controller 0 epoch 2 received response {error_code=0} for a request sent to broker Node(0, 10.139.56.24, 9092) (state.change.logger)
[2016-01-20 20:01:31,848] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2),ReplicationFactor:1),AllReplicas:0) correlation id 3 from controller 0 epoch 2 for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,848] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2),ReplicationFactor:1),AllReplicas:0) correlation id 3 from controller 0 epoch 2 for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,848] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 2 starting the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,849] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 2 starting the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,850] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 2 for partition [twitterStream,0] since it is already the leader for the partition. (state.change.logger)
[2016-01-20 20:01:31,851] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 2 for partition [twitterstream,0] since it is already the leader for the partition. (state.change.logger)
[2016-01-20 20:01:31,851] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 2 for the become-leader transition for partition [twitterStream,0] (state.change.logger)
[2016-01-20 20:01:31,851] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 2 for the become-leader transition for partition [twitterstream,0] (state.change.logger)
[2016-01-20 20:01:31,852] TRACE Controller 0 epoch 2 received response {error_code=0,partitions=[{topic=twitterStream,partition=0,error_code=0},{topic=twitterstream,partition=0,error_code=0}]} for a request sent to broker Node(0, 10.139.56.24, 9092) (state.change.logger)
[2016-01-20 20:01:31,853] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2),ReplicationFactor:1),AllReplicas:0) for partition [twitterStream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 4 (state.change.logger)
[2016-01-20 20:01:31,854] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:1,ControllerEpoch:2),ReplicationFactor:1),AllReplicas:0) for partition [twitterstream,0] in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 4 (state.change.logger)
[2016-01-20 20:01:31,854] TRACE Controller 0 epoch 2 received response {error_code=0} for a request sent to broker Node(0, 10.139.56.24, 9092) (state.change.logger)
